{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"Day43_define_network_HW.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bv6b8iLk0mUT","colab_type":"text"},"source":["### 作業\n","請嘗試使用 keras 來定義一個直接預測 15 個人臉關鍵點坐標的檢測網路，以及適合這個網路的 loss function\n","\n","\n","Hint: 參考前面的電腦視覺深度學習基礎"]},{"cell_type":"markdown","metadata":{"id":"YjYEB4WJ0mUV","colab_type":"text"},"source":["### 範例\n","接下來的程式碼會示範如何定義一個簡單的 CNN model"]},{"cell_type":"code","metadata":{"id":"oN90kb5C0mUX","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DBFM-5Y0mUf","colab_type":"code","outputId":"af33df9e-9930-448d-9653-bc080beda365","executionInfo":{"status":"ok","timestamp":1591276499786,"user_tz":-480,"elapsed":2514,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["# 使用 colab 環境的同學請執行以下程式碼\n","%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import os\n","from google.colab import drive \n","drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n","%cd 'gdrive/My Drive/'\n","# os.system(\"mkdir cupoy_cv_part4\") # 可以自己改路徑\n","# %cd cupoy_cv_part4 # 可以自己改路徑"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","1.15.2\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SReVhayPeJDM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"e795de56-d4e0-4a54-d716-461917a207bb","executionInfo":{"status":"ok","timestamp":1591276524707,"user_tz":-480,"elapsed":2854,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}}},"source":["%pwd\n","%ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":[" \u001b[0m\u001b[01;34m2020_02_07_備份\u001b[0m/                           \u001b[01;34m'L_For Language Center'\u001b[0m/\n","\u001b[01;34m'A_For Application Form'\u001b[0m/                   \u001b[01;34m'M_For Movie Watching'\u001b[0m/\n","\u001b[01;34m'B_For Boomerang'\u001b[0m/                          \u001b[01;34m'N_For NCU Record'\u001b[0m/\n","\u001b[01;34m'C_For CT Squad'\u001b[0m/                            \u001b[01;34mO_For_\u001b[0m/\n"," \u001b[01;34mClassroom\u001b[0m/                                 \u001b[01;34m'P_For PPT Only'\u001b[0m/\n"," \u001b[01;34mD_For_Data_Scientist\u001b[0m/                       \u001b[01;34mQ_For_\u001b[0m/\n","\u001b[01;34m'E_For ENGLISH SPANISH JAPANESE Learning'\u001b[0m/  \u001b[01;34m'R_For Recording Video'\u001b[0m/\n"," \u001b[01;34mF_For_\u001b[0m/                                    'Schedule Up.gsheet'\n","\u001b[01;34m'G_For Group Photo'\u001b[0m/                         \u001b[01;34mS_For_\u001b[0m/\n"," \u001b[01;34mH_For_\u001b[0m/                                     \u001b[01;34mT_For_\u001b[0m/\n","\u001b[01;34m'I_For Identification Photo'\u001b[0m/                \u001b[01;34mU_For_\u001b[0m/\n","\u001b[01;34m'J_For Journey Photo'\u001b[0m/                      \u001b[01;34m'V_For Edited Video'\u001b[0m/\n"," \u001b[01;34mkeras-yolo3\u001b[0m/                                \u001b[01;34mW_For_\u001b[0m/\n","\u001b[01;34m'K_For Kanna San <3'\u001b[0m/                        \u001b[01;34mX_For_\u001b[0m/\n","\u001b[01;34m'LeftHand Project'\u001b[0m/                          \u001b[01;34mY_For_\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AIpmmhxpcHYG","colab_type":"code","outputId":"9dadc028-1d8a-48d6-f6fa-5a4cfd36e83e","executionInfo":{"status":"ok","timestamp":1591276533673,"user_tz":-480,"elapsed":1271,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd \"D_For_Data_Scientist/Computer Vision/temp/Day42\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/D_For_Data_Scientist/Computer Vision/temp/Day42\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UGz6eqLgcmDb","colab_type":"code","outputId":"49fd4b74-5eab-4e4a-9ffd-4251a7b2e3bf","executionInfo":{"status":"ok","timestamp":1591276550485,"user_tz":-480,"elapsed":2808,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["%ls"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Day42_explore_facial_keypoint_data_HW.ipynb      test.csv\n","Day42_explore_facial_keypoint_data_Sample.ipynb  training.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uv7PdJWT0mUj","colab_type":"code","colab":{}},"source":["# 讀取資料集以及做前處理的函數\n","def load_data(dirname):\n","    # 讀取 csv 文件\n","    data = pd.read_csv(dirname)\n","    # 過濾有缺失值的 row\n","    data = data.dropna()\n","\n","    # 將圖片像素值讀取為 numpy array 的形態\n","    data['Image'] = data['Image'].apply(lambda img: np.fromstring(img, sep=' ')).values \n","\n","    # 單獨把圖像 array 抽取出來\n","    imgs = np.vstack(data['Image'].values)/255\n","    # reshape 為 96 x 96\n","    imgs = imgs.reshape(data.shape[0], 96, 96)\n","    # 轉換為 float\n","    imgs = imgs.astype(np.float32)\n","    \n","    # 提取坐標的部分\n","    points = data[data.columns[:-1]].values\n","\n","    # 轉換為 float\n","    points = points.astype(np.float32)\n","\n","    # normalize 坐標值到 [-0.5, 0.5]\n","    points = points/96 - 0.5\n","    \n","    return imgs, points"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWL3XmUGctnI","colab_type":"code","outputId":"33fef4cc-89fb-42d6-bd1f-2c0940a46c77","executionInfo":{"status":"ok","timestamp":1591276559130,"user_tz":-480,"elapsed":1192,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%pwd"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/My Drive/D_For_Data_Scientist/Computer Vision/temp/Day42'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"KRIIlaPD0mUm","colab_type":"code","outputId":"5be20828-0a95-45f5-acf3-c7b528abbcb2","executionInfo":{"status":"ok","timestamp":1591276569596,"user_tz":-480,"elapsed":9578,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# 讀取資料\n","imgs_train, points_train = load_data(dirname = 'training.csv')\n","print(\"圖像資料:\", imgs_train.shape, \"\\n關鍵點資料:\", points_train.shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["圖像資料: (2140, 96, 96) \n","關鍵點資料: (2140, 30)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8xkZPdsS0mUq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"54289f56-b12a-4e13-fd74-4badd748c51e","executionInfo":{"status":"ok","timestamp":1591276574143,"user_tz":-480,"elapsed":1168,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}}},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DoBPKgCd0mUt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"25347753-47e9-4029-9e1e-bf8fb5e83fc2","executionInfo":{"status":"ok","timestamp":1591276861510,"user_tz":-480,"elapsed":1157,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}}},"source":["# 定義人臉關鍵點檢測網路\n","model = Sequential()\n","\n","# 定義神經網路的輸入, hidden layer 以及輸出\n","model.add(Conv2D(filters=16, kernel_size=3,activation='relu',input_shape=(96,96,1)))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Flatten())\n","model.add(Dense(512, activation=\"relu\"))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation=\"relu\"))\n","model.add(Dropout(0.2))\n","\n","# 最後輸出30維的向量，也就是15個關鍵點的值\n","model.add(Dense(30))\n","# 配置 loss funtion 和 optimizer\n","model.compile(loss='mean_squared_error', optimizer='adam')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XOdXBUml0mUx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":622},"outputId":"fdfe56ec-5c16-4ec2-9e8a-12ed6d6c0453","executionInfo":{"status":"ok","timestamp":1591276870945,"user_tz":-480,"elapsed":1258,"user":{"displayName":"鄭中嘉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzo7L2wgzllTUh3EvDVakXV2MSAKunqERRWAZ9=s64","userId":"17757090057454546782"}}},"source":["model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 94, 94, 16)        160       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 47, 47, 16)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 45, 45, 32)        4640      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 22, 22, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 20, 20, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 8, 8, 32)          9248      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 4, 4, 32)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 30)                15390     \n","=================================================================\n","Total params: 563,998\n","Trainable params: 563,998\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]}]}